{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading some packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vchar\\anaconda3\\envs\\ml_projects\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold, RandomizedSearchCV\n",
    "from sklearn.linear_model import Lasso, Ridge\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.feature_selection import r_regression, SelectKBest\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "from boruta import BorutaPy\n",
    "\n",
    "from BorutaShap import BorutaShap\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\vchar\\\\anaconda3\\\\envs\\\\ml_projects\\\\lib\\\\site-packages\\\\boruta\\\\__init__.py'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import boruta\n",
    "\n",
    "boruta.__file__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Number of Rooms', 'Renovation', 'Furniture', 'New Construction', 'Construction Type', 'Number of Bathrooms', 'Balcony', 'Elevator']\n",
      "['Ceiling Height', 'Floor', 'Floor Area', 'Floors in the Building', 'covered parking', 'outdoor parking', 'garage', 'air conditioner', 'dishwasher', 'washing machine', 'fridge', 'drying machine', 'stove', 'park view', 'street view', 'view of Ararat', 'yard view', 'city view', 'concierge', 'intercom entry', 'playground', 'is_capital', 'city_attr_0', 'city_attr_1', 'city_attr_2', 'city_attr_3', 'city_attr_4', 'city_attr_5', 'city_attr_6', 'city_attr_7', 'city_attr_8', 'city_attr_9', 'city_attr_10', 'city_attr_11', 'metro_station_0', 'metro_station_1', 'metro_station_2', 'metro_station_3', 'metro_station_4', 'metro_station_5', 'metro_station_6', 'metro_station_7', 'metro_station_8', 'metro_station_9', 'closest_metro_distance', 'mall_0', 'mall_1', 'mall_2', 'mall_3', 'closest_mall_distance']\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = Path(r'C:/\\Users/\\vchar/\\OneDrive/\\Desktop/\\ML Projects/\\portfolio/\\ArmenianHousePrices/\\notebooks/\\data')\n",
    "\n",
    "data = pd.read_csv(os.path.join(DATA_PATH, 'final_data.csv'))\n",
    "\n",
    "cat_feats_list = list(data.select_dtypes(include=['object']).columns)\n",
    "remove_cat_list =[\n",
    "    'description', 'address', 'seller_type', 'total_description',\n",
    "    'renewed_date', 'seller_id', 'region', 'geo_location', 'estate_type'\n",
    "]\n",
    "cat_feats_list = [i for i in cat_feats_list if i not in remove_cat_list]\n",
    "cat_feats_list = ['Number of Rooms',\n",
    " 'Renovation',\n",
    " 'Furniture',\n",
    " 'New Construction',\n",
    " 'Construction Type',\n",
    " 'Number of Bathrooms',\n",
    " 'Balcony',\n",
    " 'Elevator']\n",
    "print(cat_feats_list)\n",
    "\n",
    "ordinal_feats_list = ['Number of Rooms', 'Number of Bathrooms']\n",
    "\n",
    "nominal_feats_list = [i for i in cat_feats_list if i not in ordinal_feats_list]\n",
    "\n",
    "num_feats_list = list(data.select_dtypes(exclude=['object']).columns)\n",
    "remove_num_feats_list = ['posted_date', 'sqm_price_usd', 'estate_id', 'latitude', 'longitude', 'geo_location']\n",
    "num_feats_list = [i for i in num_feats_list if i not in remove_num_feats_list and i not in cat_feats_list]\n",
    "# feats_name_list = [col for col in data.columns if col!='']\n",
    "print(num_feats_list)\n",
    "\n",
    "feats_name_list = []\n",
    "feats_name_list.extend(cat_feats_list)\n",
    "feats_name_list.extend(num_feats_list)\n",
    "\n",
    "y = data['sqm_price_usd'].copy().to_frame()\n",
    "X = data[feats_name_list].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of Rooms</th>\n",
       "      <th>Renovation</th>\n",
       "      <th>Furniture</th>\n",
       "      <th>New Construction</th>\n",
       "      <th>Construction Type</th>\n",
       "      <th>Number of Bathrooms</th>\n",
       "      <th>Balcony</th>\n",
       "      <th>Elevator</th>\n",
       "      <th>Ceiling Height</th>\n",
       "      <th>Floor</th>\n",
       "      <th>...</th>\n",
       "      <th>metro_station_6</th>\n",
       "      <th>metro_station_7</th>\n",
       "      <th>metro_station_8</th>\n",
       "      <th>metro_station_9</th>\n",
       "      <th>closest_metro_distance</th>\n",
       "      <th>mall_0</th>\n",
       "      <th>mall_1</th>\n",
       "      <th>mall_2</th>\n",
       "      <th>mall_3</th>\n",
       "      <th>closest_mall_distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.75</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>61.169827</td>\n",
       "      <td>53.006584</td>\n",
       "      <td>29.637074</td>\n",
       "      <td>244.102697</td>\n",
       "      <td>24.408433</td>\n",
       "      <td>186.156946</td>\n",
       "      <td>129.294787</td>\n",
       "      <td>124.079898</td>\n",
       "      <td>293.619775</td>\n",
       "      <td>124.079898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.75</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>139.532072</td>\n",
       "      <td>103.661085</td>\n",
       "      <td>49.488490</td>\n",
       "      <td>196.393410</td>\n",
       "      <td>22.690618</td>\n",
       "      <td>134.940334</td>\n",
       "      <td>208.131945</td>\n",
       "      <td>157.861426</td>\n",
       "      <td>300.968318</td>\n",
       "      <td>134.940334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.80</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>273.024165</td>\n",
       "      <td>324.852997</td>\n",
       "      <td>275.092613</td>\n",
       "      <td>183.363983</td>\n",
       "      <td>145.966273</td>\n",
       "      <td>198.004532</td>\n",
       "      <td>311.409442</td>\n",
       "      <td>154.460103</td>\n",
       "      <td>565.084056</td>\n",
       "      <td>154.460103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2.60</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>334.600766</td>\n",
       "      <td>265.608187</td>\n",
       "      <td>313.773654</td>\n",
       "      <td>514.741262</td>\n",
       "      <td>265.608187</td>\n",
       "      <td>454.336069</td>\n",
       "      <td>344.228264</td>\n",
       "      <td>440.023840</td>\n",
       "      <td>23.111663</td>\n",
       "      <td>23.111663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>131.678114</td>\n",
       "      <td>83.056489</td>\n",
       "      <td>42.581168</td>\n",
       "      <td>222.421567</td>\n",
       "      <td>42.581168</td>\n",
       "      <td>160.966858</td>\n",
       "      <td>197.407935</td>\n",
       "      <td>170.063984</td>\n",
       "      <td>275.782140</td>\n",
       "      <td>160.966858</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Number of Rooms  Renovation  Furniture  New Construction  \\\n",
       "0                2           0          0                 0   \n",
       "1                3           1          0                 0   \n",
       "2                2           2          1                 0   \n",
       "3                3           3          2                 0   \n",
       "4                3           4          0                 0   \n",
       "\n",
       "   Construction Type  Number of Bathrooms  Balcony  Elevator  Ceiling Height  \\\n",
       "0                  0                    1        0         0            2.75   \n",
       "1                  0                    1        1         0            2.75   \n",
       "2                  1                    1        1         1            2.80   \n",
       "3                  0                    1        2         1            2.60   \n",
       "4                  0                    1        0         0            2.80   \n",
       "\n",
       "   Floor  ...  metro_station_6  metro_station_7  metro_station_8  \\\n",
       "0      3  ...        61.169827        53.006584        29.637074   \n",
       "1     14  ...       139.532072       103.661085        49.488490   \n",
       "2      4  ...       273.024165       324.852997       275.092613   \n",
       "3      1  ...       334.600766       265.608187       313.773654   \n",
       "4      4  ...       131.678114        83.056489        42.581168   \n",
       "\n",
       "   metro_station_9  closest_metro_distance      mall_0      mall_1  \\\n",
       "0       244.102697               24.408433  186.156946  129.294787   \n",
       "1       196.393410               22.690618  134.940334  208.131945   \n",
       "2       183.363983              145.966273  198.004532  311.409442   \n",
       "3       514.741262              265.608187  454.336069  344.228264   \n",
       "4       222.421567               42.581168  160.966858  197.407935   \n",
       "\n",
       "       mall_2      mall_3  closest_mall_distance  \n",
       "0  124.079898  293.619775             124.079898  \n",
       "1  157.861426  300.968318             134.940334  \n",
       "2  154.460103  565.084056             154.460103  \n",
       "3  440.023840   23.111663              23.111663  \n",
       "4  170.063984  275.782140             160.966858  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature elimination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing low variance features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric features to remove:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Ceiling Height', 'covered parking', 'garage', 'drying machine']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variance_selector = VarianceThreshold(threshold=0.05)\n",
    "variance_selector.fit(X[num_feats_list])\n",
    "# X_selection = variance_selector.fit_transform(X[num_feats_list])\n",
    "var_selected_feats = X[num_feats_list].iloc[:, list(variance_selector.get_support())].columns.to_list()\n",
    "print('Numeric features to remove:')\n",
    "[col for col in num_feats_list if col not in var_selected_feats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(num_feats_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22157, 56)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_selection.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variance Inflation Factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_vif(X):\n",
    "    \n",
    "    vif = pd.DataFrame()\n",
    "    vif[\"features\"] = X.columns\n",
    "    vif[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "\n",
    "    return vif\n",
    "\n",
    "def select_feats_via_vif(X):\n",
    "\n",
    "    vif_df = calculate_vif(X)\n",
    "\n",
    "    while vif_df[vif_df['VIF'] >=10].shape[0] != 0:\n",
    "        vif_df.sort_values('VIF', ascending=False).reset_index(drop=True, inplace=True)\n",
    "        elimination_candidate = vif_df.iloc[0]['features']\n",
    "        new_X = X.drop(columns=elimination_candidate)\n",
    "        vif_df = calculate_vif(new_X)\n",
    "\n",
    "    return list(vif_df['features'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "sfs = SequentialFeatureSelector(knn, n_features_to_select=3, direction=”forward”)\n",
    "sfs.fit(X, y)\n",
    "X_selection = sfs.transform(X)\n",
    "\n",
    "svc = SVC(kernel=\"linear\")\n",
    "rfe = RFE(svc, n_features_to_select=3)\n",
    "rfe.fit(X, y)\n",
    "X_selection = rfe.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vchar\\anaconda3\\envs\\ml_projects\\lib\\site-packages\\sklearn\\utils\\validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Ceiling Height',\n",
       " 'Floor',\n",
       " 'New Construction',\n",
       " 'Construction Type',\n",
       " 'Number of Bathrooms',\n",
       " 'Floors in the Building',\n",
       " 'air conditioner',\n",
       " 'dishwasher',\n",
       " 'washing machine',\n",
       " 'fridge',\n",
       " 'drying machine',\n",
       " 'stove',\n",
       " 'concierge',\n",
       " 'intercom entry',\n",
       " 'is_capital']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector = SelectKBest(r_regression, k=15)\n",
    "selector.fit_transform(X[num_feats_list], y)\n",
    "selected_feats_idxs_list = list(selector.get_support(indices=True))\n",
    "column_names = [num_feats_list[i] for i in selected_feats_idxs_list]\n",
    "column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FSelector():\n",
    "\n",
    "    def __init__(self, X, y, num_feats, ordinal_feats, nominal_feats, model):\n",
    "\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.num_feats = num_feats\n",
    "        self.ordinal_feats = ordinal_feats\n",
    "        self.nominal_feats = nominal_feats\n",
    "        self.model = model\n",
    "\n",
    "    def calculate_vif(self, X):\n",
    "    \n",
    "        vif = pd.DataFrame()\n",
    "        vif[\"features\"] = X.columns\n",
    "        vif[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "\n",
    "        return vif\n",
    "\n",
    "    def select_feats_via_vif(self):\n",
    "\n",
    "        num_features = self.num_feats.copy()\n",
    "\n",
    "        vif_df = self.calculate_vif(self.X[num_features])\n",
    "\n",
    "        while vif_df[vif_df['VIF']>=10].shape[0] != 0:\n",
    "            vif_df.sort_values('VIF', ascending=False, inplace=True)\n",
    "            vif_df.reset_index(drop=True, inplace=True)\n",
    "            # print(vif_df)\n",
    "            elimination_candidate = vif_df.iloc[0]['features']\n",
    "            # print(elimination_candidate)\n",
    "            num_features = [i for i in num_features if i!=elimination_candidate]\n",
    "            new_X = self.X[num_features]\n",
    "            vif_df = self.calculate_vif(new_X)\n",
    "\n",
    "        return list(vif_df['features'].values)\n",
    "    \n",
    "    def get_spearmanr(self):\n",
    "        return [stats.spearmanr(self.X.values[:, f], self.y.values).correlation for f in range(self.X.shape[1])]\n",
    "    \n",
    "    def get_kendalltau(self):\n",
    "        return [stats.kendalltau(self.X.values[:, f], self.y.values).correlation for f in range(self.X.shape[1])]\n",
    "    \n",
    "    def get_pointbiserialr(self):\n",
    "        return [stats.pointbiserialr(self.X.values[:, f], self.y.values).correlation for f in range(self.X.shape[1])]\n",
    "    \n",
    "    def get_boruto_feats(self, model):\n",
    "        feat_selector = BorutaPy(model, n_estimators='auto', verbose=2, random_state=1)\n",
    "        feat_selector.fit(np.array(self.X), np.array(self.y))\n",
    "        return feat_selector.support_\n",
    "    \n",
    "    def get_kbest(self, X, feats_list, metric, k=15):\n",
    "        selector = SelectKBest(metric, k=k)\n",
    "        selector.fit_transform(X[feats_list], self.y)\n",
    "        selected_feats_idxs_list = list(selector.get_support(indices=True))\n",
    "        column_names = [num_feats_list[i] for i in selected_feats_idxs_list]\n",
    "        return column_names\n",
    "    \n",
    "    def get_votes(self):\n",
    "\n",
    "        if self.num_feats is not None:\n",
    "\n",
    "            self.vif_feats = self.select_feats_via_vif()\n",
    "\n",
    "            self.pearson_feats = self.get_kbest(X=self.X, feats_list=self.num_feats, metric=r_regression, k=15)\n",
    "            # self.num_spearmanr_feats = self.get_kbest(X=self.X, feats_list=self.num_feats, metric=stats.spearmanr, k=15)\n",
    "            # self.num_kendalltau_feats = self.get_kbest(X=self.X, feats_list=self.num_feats, metric=stats.kendalltau, k=15)\n",
    "\n",
    "            # self.num_spearmanr_feats = SelectKBest(self.get_spearmanr, k=15).fit_transform(self.X[self.num_feats], self.y)\n",
    "            # self.num_kendalltau_feats = SelectKBest(self.get_kendalltau, k=15).fit_transform(self.X[self.num_feats], self.y)\n",
    "\n",
    "            self.selected_num_feats = []\n",
    "            self.selected_num_feats.extend(self.pearson_feats)\n",
    "            # self.selected_num_feats.extend(self.num_spearmanr_feats)\n",
    "            # self.selected_num_feats.extend(self.num_kendalltau_feats)\n",
    "            # self.selected_num_feats = list(set(self.selected_num_feats))\n",
    "\n",
    "        if self.ordinal_feats is not None:\n",
    "\n",
    "            # self.ordinal_spearmanr_feats = self.get_kbest(X=self.X, feats_list=self.ordinal_feats, metric=stats.spearmanr, k=15)\n",
    "            # self.ordinal_kendalltau_feats = self.get_kbest(X=self.X, feats_list=self.ordinal_feats, metric=stats.kendalltau, k=15)\n",
    "\n",
    "            # self.ordinal_spearmanr_feats = SelectKBest(self.get_spearmanr, k=15).fit_transform(self.X[self.ordinal_feats], self.y)\n",
    "            # self.ordinal_kendalltau_feats = SelectKBest(self.get_kendalltau, k=15).fit_transform(self.X[self.ordinal_feats], self.y)\n",
    "\n",
    "            self.selected_ordinal_feats = []\n",
    "            self.selected_ordinal_feats.extend(self.ordinal_spearmanr_feats)\n",
    "            self.selected_ordinal_feats.extend(self.ordinal_kendalltau_feats)\n",
    "            # self.selected_ordinal_feats = list(set(self.selected_ordinal_feats))\n",
    "\n",
    "        if self.nominal_feats is not None:\n",
    "\n",
    "            # self.f_feats = self.get_kbest(X=self.X, feats_list=self.nominal_feats, metric=f_classif, k=15)\n",
    "            # self.mi_feats = self.get_kbest(X=self.X, feats_list=self.nominal_feats, metric=mutual_info_regression, k=15)\n",
    "\n",
    "            # # self.f_feats = f_classif(self.X[self.nominal_feats], self.y)[0]\n",
    "            # self.f_feats = SelectKBest(f_classif, k=15).fit_transform(self.X[self.nominal_feats], self.y).columns\n",
    "            \n",
    "            # # self.mi_feats = mutual_info_regression(self.X[self.nominal_feats], self.y)\n",
    "            # self.mi_feats = SelectKBest(mutual_info_regression, k=15).fit_transform(self.X[self.nominal_feats], self.y).columns\n",
    "\n",
    "            self.selected_nominal_feats = []\n",
    "            self.selected_nominal_feats.extend(self.f_feats)\n",
    "            self.selected_nominal_feats.extend(self.mi_feats)\n",
    "            # self.selected_nominal_feats = list(set(self.selected_nominal_feats))\n",
    "\n",
    "        if self.model is not None:\n",
    "            # np.int = np.int32\n",
    "            # np.float = np.float64\n",
    "            # np.bool = np.bool_\n",
    "            self.boruto_feats =  self.get_boruto_feats(self.model)\n",
    "\n",
    "        self.selected_num_feats.extend(self.boruto_feats)\n",
    "        num_feats_dict = dict(Counter(self.selected_num_feats))\n",
    "        self.selected_num_feats = [i for i in num_feats_dict if num_feats_dict[i] >= 2]\n",
    "\n",
    "        # self.selected_ordinal_feats.extend(self.boruto_feats)\n",
    "        # ordinal_feats_dict = dict(Counter(self.selected_ordinal_feats))\n",
    "        # self.selected_ordinal_feats = [i for i in ordinal_feats_dict if ordinal_feats_dict[i] >= 2]\n",
    "\n",
    "        # self.selected_nominal_feats.extend(self.boruto_feats)\n",
    "        # nominal_feats_dict = dict(Counter(self.selected_nominal_feats))\n",
    "        # self.selected_nominal_feats = [i for i in nominal_feats_dict if nominal_feats_dict[i] >= 2]\n",
    "\n",
    "        self.selected_feats = []\n",
    "        self.selected_feats.extend(self.selected_num_feats)\n",
    "        # self.selected_feats.extend(self.selected_ordinal_feats)\n",
    "        # self.selected_feats.extend(self.selected_nominal_feats)\n",
    "        self.selected_feats.extend(self.boruto_feats)\n",
    "\n",
    "        return self.selected_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fselector.get_boruto_feats(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fselector = FSelector(\n",
    "#     X=X, \n",
    "#     y=y, \n",
    "#     num_feats=num_feats_list, \n",
    "#     ordinal_feats=ordinal_feats_list, \n",
    "#     nominal_feats=nominal_feats_list, \n",
    "#     model=model\n",
    "# )\n",
    "\n",
    "# fselector.select_feats_via_vif()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models_list = [RandomForestRegressor(), XGBRegressor(), LGBMRegressor()]\n",
    "# model_names_list = ['RandomForestRegressor', 'XGBRegressor', 'LGBMRegressor']\n",
    "\n",
    "# for i in range(len(models_list)):\n",
    "\n",
    "#     model = models_list[i]\n",
    "    \n",
    "#     fselector = FSelector(\n",
    "#         X=X, \n",
    "#         y=y, \n",
    "#         num_feats=num_feats_list, \n",
    "#         ordinal_feats=None, \n",
    "#         nominal_feats=None, \n",
    "#         model=model\n",
    "#     )\n",
    "\n",
    "#     selected_feats_list = fselector.get_votes()\n",
    "\n",
    "#     print(f\"{model_names_list}: {selected_feats_list}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor()\n",
    "rf_rfe = RFE(rf, n_features_to_select=15)\n",
    "rf_rfe.fit(X, y)\n",
    "# X_selection = rf_rfe.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Renovation', 'Furniture', 'Construction Type', 'Ceiling Height',\n",
       "       'Floor', 'Floor Area', 'Floors in the Building', 'is_capital',\n",
       "       'latitude', 'longitude', 'city_attr_3', 'city_attr_4', 'city_attr_8',\n",
       "       'mall_2', 'closest_mall_distance'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_rfe_feats = X.iloc[:, list(rf_rfe.support_)].columns\n",
    "rf_rfe_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbr = XGBRegressor()\n",
    "xgb_rfe = RFE(xgbr, n_features_to_select=15)\n",
    "xgb_rfe.fit(X, y)\n",
    "# X_selection = xgb_rfe.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Renovation', 'Furniture', 'New Construction', 'Construction Type',\n",
       "       'Number of Bathrooms', 'Elevator', 'Ceiling Height', 'Floor Area',\n",
       "       'Floors in the Building', 'air conditioner', 'view of Ararat',\n",
       "       'concierge', 'intercom entry', 'playground', 'is_capital'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_rfe_feats = X.iloc[:, list(xgb_rfe.support_)].columns\n",
    "xgb_rfe_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbmr = LGBMRegressor()\n",
    "lgbmr_rfe = RFE(lgbmr, n_features_to_select=15)\n",
    "lgbmr_rfe.fit(X, y)\n",
    "# X_selection = lgbmr_rfe.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Number of Rooms', 'Renovation', 'Furniture', 'Construction Type',\n",
       "       'Balcony', 'Ceiling Height', 'Floor', 'Floor Area',\n",
       "       'Floors in the Building', 'latitude', 'longitude',\n",
       "       'closest_metro_distance', 'mall_1', 'mall_2', 'closest_mall_distance'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbmr_rfe_feats = X.iloc[:, list(lgbmr_rfe.support_)].columns\n",
    "lgbmr_rfe_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "selector = BorutaShap(importance_measure='shap', classification=False)\n",
    "selector.fit(X=X, y=y, n_trials=100, sample=False, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_remove = selector.features_to_remove\n",
    "boruta_shap_selected_feats = [col for col in feats_name_list if col not in features_to_remove]\n",
    "boruta_shap_selected_feats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fold creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# cv_split_list = []\n",
    "\n",
    "# for train_idxs, valid_idxs in kfold.split(X):\n",
    "#     cv_split_list.append((train_idxs, valid_idxs))\n",
    "\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=13)\n",
    "kf_cv_list = [idxs for idxs in kf.split(X)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_rfecv = RFECV(\n",
    "    RandomForestRegressor(),\n",
    "    cv=kf_cv_list\n",
    ")\n",
    "rf_rfecv.fit(X, y)\n",
    "\n",
    "rf_rfecv_feats = X.iloc[:, list(rf_rfecv.support_)].columns\n",
    "rf_rfecv_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_rfecv = RFECV(\n",
    "    XGBRegressor(),\n",
    "    cv=kf_cv_list\n",
    ")\n",
    "xgb_rfecv.fit(X, y)\n",
    "\n",
    "xgb_rfecv_feats = X.iloc[:, list(xgb_rfecv.support_)].columns\n",
    "xgb_rfecv_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_rfecv = RFECV(\n",
    "    LGBMRegressor(),\n",
    "    cv=kf_cv_list\n",
    ")\n",
    "lgbm_rfecv.fit(X, y)\n",
    "\n",
    "lgbm_rfecv_feats = X.iloc[:, list(lgbm_rfecv.support_)].columns\n",
    "lgbm_rfecv_feats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model construction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators_list = [25, 50, 100, 120, 300, 500]#, 800, 1200]\n",
    "\n",
    "max_depth_list = [5, 8, 15, 25, 30, None]\n",
    "\n",
    "min_samples_split_list = [2, 5, 10, 15, 100]\n",
    "\n",
    "min_samples_leaf_list = [2, 5, 10]\n",
    "\n",
    "max_features_list = ['log2', 'sqrt', None]\n",
    "\n",
    "params_dict={\n",
    "    'n_estimators': n_estimators_list,\n",
    "    'max_depth': max_depth_list,\n",
    "    'min_samples_split': min_samples_split_list,\n",
    "    'min_samples_leaf': min_samples_leaf_list,\n",
    "    'max_features': max_features_list\n",
    "}\n",
    "\n",
    "# rf_gscv = GridSearchCV(\n",
    "#     RandomForestRegressor(),\n",
    "#     param_grid=params_dict,\n",
    "#     scoring='neg_mean_squared_error',\n",
    "#     cv=kf_cv_list,\n",
    "#     n_jobs=-1,\n",
    "#     verbose=4\n",
    "# )\n",
    "\n",
    "rf_rscv = RandomizedSearchCV(\n",
    "    RandomForestRegressor(),\n",
    "    param_distributions=params_dict,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    cv=kf_cv_list,\n",
    "    n_jobs=-1,\n",
    "    verbose=4,\n",
    "    n_iter=30,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "rf_rscv.fit(X[rf_rfecv_feats], y)\n",
    "\n",
    "print(rf_rscv.best_params_)\n",
    "print(-rf_rscv.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eta_list = [0.01, 0.015, 0.025, 0.05, 0.1, 0.3]\n",
    "\n",
    "gamma_list = [0, 0.05, 0.07, 0.09, 0.1, 0.3, 0.5, 0.7, 0.9, 1.0]\n",
    "\n",
    "max_depth_list = [3, 5, 6, 7, 9, 12, 15, 17, 25]\n",
    "\n",
    "min_child_weight_list = [1, 3, 5, 7]\n",
    "\n",
    "subsample_list = [0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "\n",
    "colsample_bytree_list = [0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "\n",
    "lambda_list = [0.01, 0.03, 0.1, 1.0]\n",
    "\n",
    "alpha_list = [0, 0.1, 0.5, 1.0]\n",
    "\n",
    "\n",
    "params_dict={\n",
    "    'eta': eta_list,\n",
    "    'gamma': gamma_list,\n",
    "    'max_depth': max_depth_list,\n",
    "    'min_child_weight': min_child_weight_list,\n",
    "    'subsample': subsample_list,\n",
    "    'colsample_bytree': colsample_bytree_list,\n",
    "    'lambda': lambda_list,\n",
    "    'alpha': alpha_list\n",
    "}\n",
    "\n",
    "\n",
    "xgb_rscv = RandomizedSearchCV(\n",
    "    XGBRegressor(),\n",
    "    param_distributions=params_dict,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    cv=kf_cv_list,\n",
    "    n_jobs=-1,\n",
    "    verbose=4,\n",
    "    n_iter=30,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "xgb_rscv.fit(X[xgb_rfecv_feats], y)\n",
    "\n",
    "print(xgb_rscv.best_params_)\n",
    "print(-xgb_rscv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "params_dict ={\n",
    "    'num_leaves': [i for i in range(1, 100)],\n",
    "    #'min_child_samples': np.random.randint(100, 500),\n",
    "    'min_child_weight': [1e-5, 1e-3, 1e-2, 1e-1, 1, 1e1, 1e2, 1e3, 1e4],\n",
    "    #'subsample': sp_uniform(loc=0.2, scale=0.8),\n",
    "    #'colsample_bytree': sp_uniform(loc=0.4, scale=0.6),\n",
    "    'reg_alpha': [0, 1e-1, 1, 2, 5, 7, 10, 50, 100],\n",
    "    'reg_lambda': [0, 1e-1, 1, 5, 10, 20, 50, 100],\n",
    "    'max_depth': [-1, 1, 2, 3, 4, 5, 6, 7],\n",
    "    'n_estimators': [i for i in range(5, 1000, 10)],\n",
    "    'learning_rate': [0.0001,0.0005,0.001,0.005,0.01,0.05,0.1],\n",
    "    'feature_fraction': [0.1, 0.5], #set=, subsample= will be ignored\n",
    "    'bagging_fraction': [0.1, 0.5], #set=,subsample= will be ignored\n",
    "    'min_data_in_leaf': [i for i in range(10, 500, 10)], #set=, min_child_samples=\n",
    "}\n",
    "\n",
    "\n",
    "# params_dict = {\n",
    "#     'bagging_fraction': (0.5, 0.8),\n",
    "#     'bagging_frequency': (5, 8),\n",
    "#     'feature_fraction': (0.5, 0.8),\n",
    "#     'max_depth': (10, 13),\n",
    "#     'min_data_in_leaf': (90, 120),\n",
    "#     'num_leaves': (1200, 1550)\n",
    "# }\n",
    "\n",
    "\n",
    "lgbm_rscv = RandomizedSearchCV(\n",
    "    LGBMRegressor(),\n",
    "    param_distributions=params_dict,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    cv=kf_cv_list,\n",
    "    n_jobs=-1,\n",
    "    verbose=4,\n",
    "    n_iter=30,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "lgbm_rscv.fit(X[lgbm_rfecv_feats], y)\n",
    "\n",
    "print(lgbm_rscv.best_params_)\n",
    "print(-lgbm_rscv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove numeric features with low variance\n",
    "# use vif to eliminate correlated features\n",
    "# use mutual_info for preliminary feature elimination\n",
    "# RandomForest: use scores to eliminate features\n",
    "# XGBoost: use scores to eliminate features\n",
    "# LightGBM: use scores to eliminate features\n",
    "\n",
    "# create one hot features\n",
    "# Lasso: eliminate features with 0 coefficients\n",
    "# SVM: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_pipeline = Pipeline(\n",
    "#     steps=[\n",
    "#         ('imputer', SimpleImputer(strategy='median')),\n",
    "#         ('scaler', StandardScaler())\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# cat_pipeline = Pipeline(\n",
    "#     steps=[\n",
    "#         ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "#         ('ordinalencoder', OrdinalEncoder(categories=[list different categories here])),\n",
    "#         ('scaler', StandardScaler())\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# preprocessor = ColumnTransformer(\n",
    "#     ('num_pipeline', num_pipeline, numerical_cols),\n",
    "#     ('cat_pipeline', cat_pipeline, cat_cols)\n",
    "# )\n",
    "\n",
    "# preprocessor.fit_transform(), preprocessor.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_projects",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
